{"perimeter": "default", "project": "crypto_anomaly", "branch": "main", "version_id": "cf6c905c752fa2ca229c8175372043c2a77451ac", "spec": {"metaflow_project": "crypto_anomaly", "metaflow_branch": "prod", "card_info": [], "code": [{"display_name": "add outerbounds pkg (cf6c90)", "url": "https://no-commit-url/cf6c905c752fa2ca229c8175372043c2a77451ac"}], "created_at": "2025-09-17T15:15:57Z", "data": [{"display_name": "Evaluation Results", "id": "evaluation_results", "card_markdown": "", "description": "Model evaluation records with anomaly detection metrics"}, {"display_name": "Market Snapshot", "id": "market_snapshot", "card_markdown": "", "description": "Live cryptocurrency market data from CoinGecko"}], "deployment_events": [{"commit_sha": "cf6c905c752fa2ca229c8175372043c2a77451ac", "commit_link": "https://no-commit-url/cf6c905c752fa2ca229c8175372043c2a77451ac", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "add outerbounds pkg", "timestamp": "2025-09-18T14:02:26-07:00"}, {"commit_sha": "8f5b1cb34b927dfe85179338d2982891717c0a57", "commit_link": "https://no-commit-url/8f5b1cb34b927dfe85179338d2982891717c0a57", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "add pillow", "timestamp": "2025-09-18T13:59:49-07:00"}, {"commit_sha": "09a9bb4b55dced7c125a94a8160c78d4275e4ac9", "commit_link": "https://no-commit-url/09a9bb4b55dced7c125a94a8160c78d4275e4ac9", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "add ob package", "timestamp": "2025-09-18T13:55:41-07:00"}, {"commit_sha": "4ae7a097c8cf9b4245eb385040debccfd5a61b05", "commit_link": "https://no-commit-url/4ae7a097c8cf9b4245eb385040debccfd5a61b05", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "fix busted routes", "timestamp": "2025-09-18T13:46:30-07:00"}, {"commit_sha": "91c5d65c23cbb3f599e5e42659c20fd2406464eb", "commit_link": "https://no-commit-url/91c5d65c23cbb3f599e5e42659c20fd2406464eb", "owner": "40632488+emattia@users.noreply.github.com", "pr_description": "", "pr_title": "Update deploy.yml", "timestamp": "2025-09-18T13:34:56-07:00"}, {"commit_sha": "41527426e64f35146a61ff37e72bc057ab4bbf3e", "commit_link": "https://no-commit-url/41527426e64f35146a61ff37e72bc057ab4bbf3e", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "shorten names...", "timestamp": "2025-09-18T11:59:37-07:00"}, {"commit_sha": "d5c4528e9d734c67d11c442c44a7a1449f758a9a", "commit_link": "https://no-commit-url/d5c4528e9d734c67d11c442c44a7a1449f758a9a", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "organize deployments", "timestamp": "2025-09-18T11:58:19-07:00"}, {"commit_sha": "0fe3a3452f6b3f5fbcd0a40db6632ece830f40a0", "commit_link": "https://no-commit-url/0fe3a3452f6b3f5fbcd0a40db6632ece830f40a0", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "yaml->yml", "timestamp": "2025-09-18T11:55:20-07:00"}, {"commit_sha": "35826d17302a046ae663fcfc2113c146f327f29f", "commit_link": "https://no-commit-url/35826d17302a046ae663fcfc2113c146f327f29f", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "fix batch_infer_queue project", "timestamp": "2025-09-18T11:54:03-07:00"}, {"commit_sha": "5045b715edc4af328b0d43dc524c728ed8d72c7e", "commit_link": "https://no-commit-url/5045b715edc4af328b0d43dc524c728ed8d72c7e", "owner": "eddie@outerbounds.com", "pr_description": "", "pr_title": "sync project", "timestamp": "2025-09-18T11:49:56-07:00"}], "markdown": "# Crypto Market Anomaly Detection\n\nReal-time anomaly detection on live cryptocurrency market data from CoinGecko.\n\n## Model Lifecycle\n\nThis project uses the **champion/challenger** pattern for model lifecycle:\n\n| Status | Meaning | How it's set |\n|--------|---------|--------------|\n| `candidate` | Newly trained, not yet evaluated | TrainAnomalyFlow |\n| `evaluated` | Passed point-in-time quality gates | EvaluateAnomalyFlow |\n| `challenger` | Running in parallel with champion | Deployment config |\n| `champion` | Primary model, blessed for serving | PromoteAnomalyFlow |\n| `retired` | Previous champion, replaced | (when new champion is promoted) |\n\nThe idea that will become important is to view these states as ML Asset quality designations, and not confuse such status tags with deployment environments.\n- A `champion` model can be deployed to dev, staging, OR prod\n- Deployment configs can then reference models by alias (`champion`) or version (`v5`)\n- The intent is clean separation of \"is this model performant enough to serve production traffic?\" from \"which code/project branch is this model on?\"\n\n### Evaluated vs Challenger\n\nThe distinction matters:\n\n- **`evaluated`**: Point-in-time assessment. A single evaluation run passed quality gates. This is necessary but may not be sufficient in most real-world systems.\n- **`challenger`**: Trial period. The model runs in parallel with the champion over time, allowing comparison of Evals.log streams. This applies to BOTH:\n  - **Batch workflows**: Parallel daily/hourly runs with different model refs\n  - **API deployments**: Traffic split between deployment variants\n\n```\ncandidate \u2500\u2500\u25ba evaluated \u2500\u2500\u25ba challenger \u2500\u2500\u25ba champion\n                \u2502               \u2502\n          Point-in-time    Trial period\n          (single run)     (parallel runs)\n```\n## Project Structure\n\n```\n\u251c\u2500\u2500 src/                   # Core operational logic (reusable)\n\u2502   \u251c\u2500\u2500 data.py            # Data fetching, feature engineering\n\u2502   \u251c\u2500\u2500 model.py           # Model training, inference\n\u2502   \u251c\u2500\u2500 registry.py        # Asset registration, versioning\n\u2502   \u2514\u2500\u2500 eval.py            # Evaluation, quality gates\n\u2502\n\u251c\u2500\u2500 flows/                 # Thin orchestration layers\n\u2502   \u251c\u2500\u2500 ingest/flow.py     # Orchestrates: fetch \u2192 extract \u2192 register DataAsset\n\u2502   \u251c\u2500\u2500 train/flow.py      # Orchestrates: load data \u2192 train \u2192 register ModelAsset\n\u2502   \u251c\u2500\u2500 evaluate/flow.py   # Orchestrates: load \u2192 predict \u2192 gates \u2192 update\n\u2502   \u2514\u2500\u2500 promote/flow.py    # Orchestrates: load \u2192 promote \u2192 publish\n\u2502\n\u251c\u2500\u2500 deployments/\n\u2502   \u2514\u2500\u2500 api/app.py         # FastAPI service (uses src modules)\n\u2502\n\u251c\u2500\u2500 data/                   # DataAsset configs\n\u2502   \u2514\u2500\u2500 market_snapshot/\n\u2514\u2500\u2500 models/                 # ModelAsset configs\n    \u2514\u2500\u2500 anomaly_detector/\n```\n\n### Why `/src` at project root?\n\nSeparating operational logic from orchestration enables:\n\n1. **Dependency injection** - Config files can specify which code paths to use\n2. **Dynamic loading** - Different asset states trigger different behaviors\n3. **Testability** - Test workflows independently of flow orchestration\n4. **Reusability** - Same logic in flows, API, and notebooks\n\n```python\n# In a flow\nfrom src import data, model, registry\nsnapshot = data.fetch_market_data()\nfeature_set = data.extract_features(snapshot)\ntrained, result = model.train(feature_set)\nregistry.register_model(prj, \"anomaly_detector\", ...)\n\n# In API\nfrom src import data, model\nsnapshot = data.fetch_market_data()\nprediction = model.predict_fresh(config, data.extract_features(snapshot))\n\n# In notebook\nfrom src import data\nsnapshot = data.fetch_market_data()\ndata.get_top_movers(snapshot)\n```\n\n## ML Lifecycle\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         ML LIFECYCLE                             \u2502\n\u2502                                                                  \u2502\n\u2502   TrainFlow \u2500\u2500\u2500\u2500\u2500\u2500\u25ba EvaluateFlow \u2500\u2500\u2500\u2500\u2500\u2500\u25ba PromoteFlow            \u2502\n\u2502       \u2502                  \u2502                    \u2502                  \u2502\n\u2502       \u25bc                  \u25bc                    \u25bc                  \u2502\n\u2502   candidate          evaluated            champion              \u2502\n\u2502   (new model)     (gates passed)       (blessed for            \u2502\n\u2502                                          serving)               \u2502\n\u2502                                                                  \u2502\n\u2502   Optional: Deploy as 'challenger' for trial period             \u2502\n\u2502   before promoting to champion                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DEPLOYMENT CONFIGS                            \u2502\n\u2502                    (in git branches)                             \u2502\n\u2502                                                                  \u2502\n\u2502   git:main     \u2192  model_ref: \"anomaly_detector:latest\"          \u2502\n\u2502   git:staging  \u2192  model_ref: \"anomaly_detector:champion\"        \u2502\n\u2502   git:prod     \u2192  model_ref: \"anomaly_detector:v5\"  (pinned)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## Flows\n\n### IngestMarketDataFlow\n\nFetches live data, registers versioned `market_snapshot` DataAsset:\n\n```bash\npython flows/ingest/flow.py run\npython flows/ingest/flow.py run --num_coins 200\n```\n\n### TrainAnomalyFlow\n\nTrains model, registers as `candidate`. Can use registered data or fetch fresh:\n\n```bash\n# Quick testing (fetch fresh data)\npython flows/train/flow.py run --contamination 0.10\n\n# Production (use registered data asset for lineage)\npython flows/train/flow.py run --data_version latest\n```\n\n### EvaluateAnomalyFlow\n\nEvaluates candidate, applies quality gates, updates status to `evaluated`:\n\n```bash\npython flows/evaluate/flow.py run --max_anomaly_rate 0.20\n```\n\n### PromoteAnomalyFlow\n\nPromotes model to `champion` status:\n\n```bash\npython flows/promote/flow.py run --version latest\n```\n\n## API\n\nThe API tries to load `champion` first, falls back to `latest`:\n\n| Endpoint | Description |\n|----------|-------------|\n| `POST /scan` | Scan market for anomalies |\n| `GET /anomalies` | Get detected anomalies |\n| `GET /market` | Market overview |\n| `GET /model/info` | Model info (status: candidate/evaluated/champion) |\n| `POST /model/reload` | Hot-reload model |\n| `GET /versions` | List all versions |\n\n## Data Source\n\n**CoinGecko API** - Free, no API key, updates every few minutes.\n\n## Scheduling & Event Triggering\n\nWhen deployed to Argo Workflows, flows trigger automatically:\n\n```\n@schedule(hourly)          @trigger_on_finish         @trigger_on_finish\n      \u2502                           \u2502                          \u2502\n      \u25bc                           \u25bc                          \u25bc\n IngestFlow \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba TrainFlow \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba EvaluateFlow\n                                                            \u2502\n                                               publish_event(\"approval_requested\")\n                                                            \u2502\n                                                     [HUMAN REVIEW]\n                                                            \u2502\n                                              @project_trigger(\"model_approved\")\n                                                            \u25bc\n                                                      PromoteFlow\n```\n\n### Deploy to Argo\n\n```bash\n# Deploy all flows (one-time)\npython flows/ingest/flow.py --with retry argo-workflows create\npython flows/train/flow.py --with retry argo-workflows create\npython flows/evaluate/flow.py --with retry argo-workflows create\npython flows/promote/flow.py --with retry argo-workflows create\n```\n\n### Trigger Promotion (after human review)\n\n```bash\npython -c \"from obproject.project_events import ProjectEvent; \\\n    ProjectEvent('model_approved', 'crypto_anomaly', 'main').publish()\"\n```\n\n### Making Promotion Fully Automated\n\nTo skip human approval, edit `flows/promote/flow.py`:\n\n```python\n# Replace:\n@project_trigger(event=\"model_approved\")\n\n# With:\n@trigger_on_finish(flow='EvaluateAnomalyFlow')\n```\n\n### Making Promotion Manual-Only\n\nRemove the `@project_trigger` decorator entirely from PromoteFlow.\n\n## Human-in-the-Loop Stages\n\nTwo stages require human judgment (not automated by default):\n\n| Stage | Who | Decision |\n|-------|-----|----------|\n| **Promote to Champion** | ML Engineer | \"Is this model ready?\" (quality/business judgment) |\n| **Challenger Deployment** | Platform/MLOps | \"Deploy for A/B testing?\" (infrastructure concern) |\n\nThese are intentionally separate from flow automation because:\n- Champion promotion is a **business decision** requiring domain context\n- Challenger deployment is an **infrastructure task** (traffic splitting, monitoring)\u2014not a flow\n\n## System Extensions (Quick-Start Notes)\n\nFor teams looking to extend this system:\n\n### Approval Queue/Dashboard\n\n**Simplest approach:** Use Slack workflow or a shared spreadsheet.\n\n1. EvaluateFlow's `approval_requested` event triggers a Slack message (via Argo notification)\n2. Message includes: model version, anomaly rate, link to UI\n3. Reviewer clicks \"Approve\" button \u2192 runs a Slack workflow that calls:\n   ```bash\n   curl -X POST your-webhook/approve?version=v5\n   ```\n4. Webhook publishes `model_approved` event\n\n**Why not build a queue?** Events are fire-and-forget. Building state tracking adds complexity. Slack/JIRA already handle approval workflows well.\n\n### Challenger Traffic Splitting\n\n**Simplest approach:** Two deployment configs, manual traffic routing.\n\n1. Create `deployments/api-challenger/` with `model_ref: evaluated`\n2. Deploy both APIs to separate endpoints\n3. Use nginx/envoy/cloud load balancer to split traffic (e.g., 90/10)\n4. Monitor both via existing `/model/info` endpoint\n5. After trial period, promote challenger and remove the deployment\n\n**Why not automate?** Traffic splitting is infrastructure-specific (K8s Istio, AWS ALB, etc.). Keep flows focused on ML logic.\n\n### Rollback Automation\n\n**Simplest approach:** Manual PromoteFlow with previous version.\n\n```bash\n# Rollback to previous champion\npython flows/promote/flow.py run --version v4\n```\n\nFor automated rollback on drift detection:\n1. Create `MonitorFlow` that runs hourly, checks model performance\n2. If degraded, publish `rollback_requested` event with `--version` in payload\n3. PromoteFlow listens for this event (add second trigger)\n\n**Why start manual?** Automated rollback requires clear rollback criteria. Start with manual, learn what triggers rollback, then automate.\n\n## Customer Requirements Mapping\n\n| Requirement | Implementation |\n|-------------|----------------|\n| Create model | `models/anomaly_detector/asset_config.toml` |\n| Create version | `prj.register_model()` in TrainFlow |\n| Link to training job | Annotations: `training_run_id`, `training_flow` |\n| Link to training metrics | Annotations: `anomaly_rate`, etc. |\n| Link to training dataset | Annotations: `data_source`, `training_timestamp` |\n| Link to evaluation job | `Evals.log()` or evaluation_results asset |\n| Link to evaluation dataset | Evaluation annotations |\n| **Assign status** | `tags: {status: \"candidate/evaluated/champion\"}` |\n| Download by alias | `consume_model_asset(instance=\"champion\")` |\n| Request approval | `publish_event(\"approval_requested\")` |\n| Compare metrics | Evals comparison / EvaluateFlow card |\n| Trial period | Deploy as challenger with parallel execution |\n\n## Why Champion, Not Production?\n\nThe word \"production\" conflates two concepts:\n\n1. **ML Quality**: \"Is this model good enough?\"\n2. **Deployment Environment**: \"Where is this code running?\"\n\nBy using `champion`:\n- It's clear this is an ML quality designation\n- Deployment configs can reference `champion` from any environment\n- No confusion between model status and deploy environment\n- Clean mental model for MLOps professionals\n", "models": [{"display_name": "Anomaly Detector", "id": "anomaly_detector", "card_markdown": "", "description": "Isolation Forest model for crypto market anomaly detection"}], "perimeter": "default", "project_branch": "main", "project_name": "crypto_anomaly", "title": "Crypto Market Anomaly Detection", "updated_at": "2025-12-01T02:54:15Z", "workflows": [{"flow_name": "PromoteAnomalyFlow", "flow_template_id": "cryptoanomaly.prod.promoteanomalyflow", "markdown_description": "", "metaflow_branch": "prod", "metaflow_project": "crypto_anomaly", "tags": []}, {"flow_name": "IngestMarketDataFlow", "flow_template_id": "cryptoanomaly.prod.ingestmarketdataflow", "markdown_description": "", "metaflow_branch": "prod", "metaflow_project": "crypto_anomaly", "tags": []}, {"flow_name": "BuildDatasetFlow", "flow_template_id": "cryptoanomaly.prod.builddatasetflow", "markdown_description": "", "metaflow_branch": "prod", "metaflow_project": "crypto_anomaly", "tags": []}, {"flow_name": "EvaluateAnomalyFlow", "flow_template_id": "cryptoanomaly.prod.evaluateanomalyflow", "markdown_description": "", "metaflow_branch": "prod", "metaflow_project": "crypto_anomaly", "tags": []}, {"flow_name": "TrainAnomalyFlow", "flow_template_id": "cryptoanomaly.prod.trainanomalyflow", "markdown_description": "", "metaflow_branch": "prod", "metaflow_project": "crypto_anomaly", "tags": []}]}}